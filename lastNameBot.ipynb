{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Point criteria\n",
    "#64: guranteed ethnicity\n",
    "#32: 2 other possibilities\n",
    "#16: 3 other possibilities\n",
    "#8: 4 other possibilities\n",
    "#4: 5 other possibilities\n",
    "#2: 6 other possibilities\n",
    "#1: 7 other possibilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "points = {\n",
    "    'alb': 0,\n",
    "    'ang': 0,\n",
    "    'arm': 0,\n",
    "    'azr': 0,\n",
    "    'bsq': 0,\n",
    "    'bos': 0,\n",
    "    'scm': 0,\n",
    "    'bul': 0,\n",
    "    'cze': 0,\n",
    "    'dan': 0,\n",
    "    'est': 0,\n",
    "    'fin': 0,\n",
    "    'fre': 0,\n",
    "    'gae': 0,\n",
    "    'geo': 0,\n",
    "    'ger': 0,\n",
    "    'gre': 0,\n",
    "    'hun': 0,\n",
    "    'ice': 0,\n",
    "    'ita': 0,\n",
    "    'lat': 0,\n",
    "    'lit': 0,\n",
    "    'mlt': 0,\n",
    "    'mol': 0,\n",
    "    'dch': 0,\n",
    "    'pol': 0,\n",
    "    'por': 0,\n",
    "    'rom': 0,\n",
    "    'rus': 0,\n",
    "    'slk': 0,\n",
    "    'svn': 0,\n",
    "    'spa': 0,\n",
    "    'swe': 0,\n",
    "    'trk': 0,\n",
    "    'ukr': 0,\n",
    "    'wls': 0,\n",
    "}\n",
    "\n",
    "\n",
    "codes = {\n",
    "    'alb': 'Albanian',\n",
    "    'ang': 'English', #anglo\n",
    "    'arm': 'Armenian',\n",
    "    'azr': 'Azeri',\n",
    "    'bsq': 'Basque',\n",
    "    'bos': 'Bosniak',\n",
    "    'cro': 'Croatian',\n",
    "    'bul': 'Bulgarian',\n",
    "    'cze': 'Czech',\n",
    "    'dan': 'Danish', #dano-norwegian\n",
    "    'est': 'Estonian',\n",
    "    'fin': 'Finnish',\n",
    "    'fre': 'French',\n",
    "    'gae': 'Irish Gaelic', #gaelic\n",
    "    'geo': 'Georgian',\n",
    "    'ger': 'German', #germanic\n",
    "    'gre': 'Greek',\n",
    "    'hun': 'Hungarian',\n",
    "    'ice': 'Icelandic',\n",
    "    'ita': 'Italian',\n",
    "    'lat': 'Latvian',\n",
    "    'lth': 'Lithuanian',\n",
    "    'mlt': 'Maltese',\n",
    "    'mol': 'Moldovan',\n",
    "    'nor': 'Norwegian',\n",
    "    'dch': 'Dutch',\n",
    "    'pol': 'Polish',\n",
    "    'por': 'Portuguese',\n",
    "    'rom': 'Romanian',\n",
    "    'rus': 'Russian',\n",
    "    'slk': 'Slovakian',\n",
    "    'svn': 'Slovenian',\n",
    "    'spa': 'Spanish',\n",
    "    'srb': 'Serbian',\n",
    "    'swe': 'Swedish',\n",
    "    'trk': 'Turkish',\n",
    "    'ukr': 'Ukrainian',\n",
    "    'wls': 'Welsh',\n",
    "    \n",
    " }   \n",
    "#     Northern Ireland\n",
    "#     Belarus\n",
    "#     Faroe Islands\n",
    "#     Belarusian\n",
    "#     Belgium\n",
    "#     North Macedonia\n",
    "\n",
    "def keepOnly(*eth):\n",
    "    tempEthList = []\n",
    "    for e in eth:\n",
    "        tempEthList.append(e)\n",
    "    for key in list(points):\n",
    "        if key not in tempEthList:\n",
    "            del points[key]\n",
    "        \n",
    "def _remove(*eth):\n",
    "    deadVar = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the last name identifier. Type in a last name and see its origin.\n",
      "yo\n",
      "{}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Welcome to the last name identifier. Type in a last name and see its origin.\")\n",
    "name = input().lower()\n",
    "\n",
    "#alphabet basic\n",
    "if ('c' in name):\n",
    "    _remove('est', 'ice')\n",
    "    \n",
    "if ('j' in name):\n",
    "    _remove('gae')\n",
    "    \n",
    "if ('k' in name):\n",
    "    _remove('gae', 'ita')\n",
    "\n",
    "if ('q' in name):\n",
    "    _remove('bos', 'est', 'gae', 'ice', 'lat', 'lth','scm', 'svn', 'trk')\n",
    "    \n",
    "if ('w' in name):\n",
    "    _remove('alb', 'azr', 'gae', 'ice', 'ita', 'lat', 'lth', 'scm', 'svn', 'trk')\n",
    "\n",
    "if ('x' in name):\n",
    "    _remove('est', 'gae', 'ita', 'lat', 'lth', 'scm', 'svn', 'trk')\n",
    "    \n",
    "if ('y' in name):\n",
    "    _remove('est', 'gae', 'ita', 'scm', 'svn')\n",
    "            \n",
    "if ('z' in name):\n",
    "    _remove('gae', 'ice')\n",
    "\n",
    "    \n",
    "    \n",
    "if ('ş' in name):\n",
    "    keepOnly('aze', 'rom', 'trk')\n",
    "    \n",
    "if ('ų' in name):\n",
    "    keepOnly('lth')\n",
    "    \n",
    "if ('ł' in name):\n",
    "    keepOnly('pol')\n",
    "    \n",
    "if ('į' in name):\n",
    "    keepOnly('lth')\n",
    "    \n",
    "if ('ę' in name):\n",
    "    keepOnly('lth', 'pol')\n",
    "    \n",
    "if ('đ' in name):\n",
    "    keepOnly('scm')\n",
    "    \n",
    "if ('ç' in name):\n",
    "    keepOnly('alb', 'aze', 'fre', 'por', 'spa', 'trk')\n",
    "\n",
    "if (('ţ' in name) or ('ț' in name)):\n",
    "    keepOnly('rom')\n",
    "    \n",
    "if ('ŧ' in name):\n",
    "    keepOnly('scm')\n",
    "    \n",
    "if ('' in name):\n",
    "    keepOnly('')\n",
    "    \n",
    "if ('' in name):\n",
    "    keepOnly('')\n",
    "    \n",
    "if ('' in name):\n",
    "    keepOnly('')\n",
    "    \n",
    "if ('' in name):\n",
    "    keepOnly('')\n",
    "    \n",
    "if ('' in name):\n",
    "    keepOnly('')\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "#special characters\n",
    "\n",
    "if (('å' in name) or ('æ' in name)):\n",
    "    keepOnly('dan', 'swe')\n",
    "    \n",
    "if ('ą' in name):\n",
    "    keepOnly('lth', 'pol')\n",
    "    \n",
    "if ('ə' in name):\n",
    "    keepOnly('azr', 'tur')\n",
    "    \n",
    "if ('ı' in name):\n",
    "    keepOnly('azr', 'tur')\n",
    "\n",
    "if ('ß' in name):\n",
    "    keepOnly('ger')\n",
    "    \n",
    "if ('ð' in name):\n",
    "    keepOnly('ice', 'swe')\n",
    "    \n",
    "if ('þ' in name):\n",
    "    keepOnly('ice')\n",
    "    \n",
    "if ('œ' in name):\n",
    "    keepOnly('fre')\n",
    "\n",
    "if ('' in name):\n",
    "    keepOnly('')\n",
    "if ('' in name):\n",
    "    keepOnly('')\n",
    "if ('' in name):\n",
    "    keepOnly('')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "if ('' in name):\n",
    "    keepOnly('')\n",
    "  \n",
    "    \n",
    "    \n",
    "#carons\n",
    "if ('č' in name):\n",
    "    keepOnly('cze', 'slk', 'svn', 'scm', 'bos', 'lat', 'lth' )\n",
    "    \n",
    "if ('ď' in name):\n",
    "    keepOnly('cze', 'slk', 'svn', 'scm', 'bos', 'lat', 'lth' )\n",
    "\n",
    "\n",
    "if ('ž' in name):\n",
    "    keepOnly('cze', 'slk', 'svn', 'scm', 'bos', 'lat', 'lth' )\n",
    "\n",
    "#Armenian\n",
    "if (name.endswith('ian') or name.endswith('yan')):\n",
    "    points['arm'] += 100\n",
    "\n",
    "#Ukrainian \n",
    "#make edgecases\n",
    "if (name.endswith('enko') or name.endswith('chuk')):\n",
    "    points['ukr'] += 100\n",
    "   \n",
    "####Scandinavia\n",
    "#Dano-Norwegian/Icelandic\n",
    "if (name.endswith('sen')):\n",
    "    points['dan'] += 100\n",
    "    #############ICE?\n",
    "    \n",
    "    \n",
    "#Swedish\n",
    "if (name.endswith('sson')):\n",
    "    points['swe'] += 100\n",
    "\n",
    "####Baltic\n",
    "#Latvian\n",
    "if (name.endswith('iņš')):\n",
    "    points['lat'] += 100\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "returnStr = ''\n",
    "compareVal = 0\n",
    "for key in points:\n",
    "    if (points[key] > compareVal):\n",
    "        compareVal = points[key]\n",
    "        returnStr = key\n",
    "        \n",
    "print(points)\n",
    "print(returnStr)\n",
    "\n",
    "######\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#helloooooo\n",
    "#\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd # library for data analysis\n",
    "import requests # library to handle requests\n",
    "from bs4 import BeautifulSoup # library to parse HTML documents\n",
    "\n",
    "#fixes broken offset on lowercase letters list, leaving a clean lowercase list\n",
    "def fixAlphabet(df):\n",
    "    letter_list = []\n",
    "\n",
    "    for column in df:\n",
    "        letter_list.append(column[1])\n",
    "    letter_list[0] = 'Ethnicity'\n",
    "    df.columns = letter_list\n",
    "    return df\n",
    "\n",
    "#make list of desire eth indeces, then select only those\n",
    "def selectEths(df):\n",
    "    #print('|||||||||||||||||||')\n",
    "    for i in df.index:\n",
    "        keep = False\n",
    "        if (df.iloc[i, 0].endswith(\"]\")):\n",
    "            df.iloc[i, 0] = df.iloc[i, 0].split('[')[0]  #remove wiki footnotes\n",
    "        if df.iloc[i, 0] == 'Romani':\n",
    "            df.iloc[i, 0] = \"drop_this\" #edge case for Romani, program was confusing romani and romanian\n",
    "        for key, value in codes.items():\n",
    "            if df.iloc[i, 0] in value:                #replace the eths with codes\n",
    "                df.iloc[i, 0] = key\n",
    "                keep = True\n",
    "        if (not keep):\n",
    "           # print(\"dropped: \" + df.iloc[i, 0])              #print when we delete to make sure we didn't accidentally delete one\n",
    "            df.iloc[i, 0] = \"drop_this\"          #replace with 'drop_this otherwise'\n",
    "    \n",
    "        \n",
    "    dfcopy = df.copy()\n",
    "    for i in df.index:\n",
    "        if (df.iloc[i, 0] == \"drop_this\"):\n",
    "            dfcopy.drop(i, inplace = True)\n",
    "            \n",
    "        \n",
    "     \n",
    "    #dfcopy.reset_index(drop=True, inplace = True)\n",
    "    dfcopy.set_index('Ethnicity', inplace = True)\n",
    "\n",
    "    return dfcopy\n",
    "            \n",
    "#add missing ethnicities to the df with NaN values\n",
    "def addMissingEths(df):\n",
    "    for key in codes.keys():\n",
    "        if key not in df.index:    #if a code is not in our df yet, add it with NaN values\n",
    "            df = df.append(pd.Series(name=key, dtype='str'))        \n",
    "    return df\n",
    "\n",
    "#aggregate function to call all the methods that shape the dfs nicely\n",
    "def makeNiceDF(df):\n",
    "    df = fixAlphabet(df)\n",
    "    df = selectEths(df)\n",
    "    df = addMissingEths(df)\n",
    "    df.sort_index(inplace=True)\n",
    "    return df\n",
    "    \n",
    "    \n",
    "    \n",
    "# get the response in the form of html\n",
    "wikiurl=\"https://en.wikipedia.org/wiki/List_of_Latin-script_alphabets\"\n",
    "response=requests.get(wikiurl)\n",
    "\n",
    "#pull each table\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "print('yo')\n",
    "#letter-diacritic combos\n",
    "letter_diacritic_table = soup.find_all('table', class_=\"wikitable\")[3]  \n",
    "letter_diacritic_df = pd.read_html(str(letter_diacritic_table))\n",
    "letter_diacritic_df = pd.DataFrame(letter_diacritic_df[0])\n",
    "letter_diacritic_df = makeNiceDF(letter_diacritic_df)\n",
    "#letter_diacritic_df.dropna(axis=1, how='all', inplace=True)\n",
    "\n",
    "#letter_diacritic_df.loc['pol', 'ą'] = 'Ą'\n",
    "#manual adjustment due to wikitable[3] grouping langs\n",
    "\n",
    "print(letter_diacritic_df)\n",
    "\n",
    "#a through h table\n",
    "a_h_table = soup.find_all('table', class_=\"wikitable\")[4]  \n",
    "a_h_df = pd.read_html(str(a_h_table))\n",
    "a_h_df = pd.DataFrame(a_h_df[0])\n",
    "a_h_df = makeNiceDF(a_h_df)\n",
    "#print(a_h_df)\n",
    "\n",
    "\n",
    "#i through o table\n",
    "i_o_table = soup.find_all('table', class_=\"wikitable\")[5]  \n",
    "i_o_df = pd.read_html(str(i_o_table))\n",
    "i_o_df = pd.DataFrame(i_o_df[0])\n",
    "i_o_df = makeNiceDF(i_o_df)\n",
    "#print(i_o_df)\n",
    "\n",
    "\n",
    "#p through z table\n",
    "p_z_table = soup.find_all('table', class_=\"wikitable\")[6]  \n",
    "p_z_df = pd.read_html(str(p_z_table))\n",
    "p_z_df = pd.DataFrame(p_z_df[0])\n",
    "p_z_df = makeNiceDF(p_z_df)\n",
    "\n",
    "#print(p_z_df)\n",
    "\n",
    "#combine each df into one master df with all chars\n",
    "dfs = [a_h_df, i_o_df, p_z_df]\n",
    "char_df = pd.concat(dfs, axis=1)\n",
    "\n",
    "\n",
    "char_df = char_df.applymap(lambda s: s.lower() if type(s) == str else s) # convert all values not Nan to lowercase\n",
    "char_df.dropna(axis=1, how='all', inplace=True)\n",
    "\n",
    "\n",
    "char_df.to_csv('charTable.csv')#, index=False)\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv('charTable.csv', index_col = 0)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####TO DO###############\n",
    "In excel file, I manually removed certain chars from some languages that were excessive. Many languages had chars listed on the Wikipedia tables due to loanwords that would never occur in a native name in that language. For instance, English is listed as having Â, Ä, Û, Ü, and others. These and other symbols like them are included to facilitate integrating loanwords and foreign last names. Obviously a last name bearing one of these symbols in their name would not be of English origin."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
